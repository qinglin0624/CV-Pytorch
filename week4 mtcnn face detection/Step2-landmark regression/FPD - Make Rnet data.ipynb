{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate R-Net train&eval data list\n",
    "The purpose of this notebook is to get a txt file in the format of<br><br>\n",
    "\n",
    "`image path`||`label`+`x1` `y1` `x2` `y2`+`x1^` `y1^` `x2^` `y2^`+`d x_lefteye` `d y_lefteye` `d x_righteye` `d y_righteye`......\\n<br>\n",
    "......<br>\n",
    "\n",
    "Here, `x1^` `y1^` `x2^` `y2^` is the coordinate of a valid predicted box generated my P-Net, `x1` `y1` `x2` `y2` is the coordinate of the true box, and `d x_lefteye` `d y_lefteye` is landmark offset. With these information prepared beforehand, when R-Net is loading data, the offset can be calculated and the image can be cropped from the image instantaneously. <br>\n",
    "\n",
    "example:<br>\n",
    "```\n",
    "../input/facial-point-detection/Facial_Point_Detection/lfw_5590/Abdul_Majeed_Shobokshi_0001.jpg||p+75 89 167 181+82 97 172 187+0.3527 0.2138 0.6861 0.1527 0.6083 0.5472 0.2972 0.6805 0.5361 0.6583|...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get box and landmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setdic = {'train': 10000, 'test': 3466}\n",
    "root = '../input/facial-point-detection/Facial_Point_Detection/'\n",
    "\n",
    "def getlandmark(phase):\n",
    "    result = []\n",
    "        \n",
    "    file = open(root + phase +'ImageList.txt')\n",
    "    lines = file.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        this_img = []\n",
    "        line = line.strip()\n",
    "        contents = line.split()\n",
    "        name = contents[0]\n",
    "        box = contents[1:5]\n",
    "        landmark = contents[5:]\n",
    "        image_full_path = root + name.replace('\\\\', '/')\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_full_path)\n",
    "        except:\n",
    "            print(image_full_path)\n",
    "            continue\n",
    "            \n",
    "        result.append([image_full_path,[int(i) for i in box],[float(i) for i in landmark]])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Net and R-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class P_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(P_Net, self).__init__()\n",
    "        self.pre_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, kernel_size=3, stride=1),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(10, 16, kernel_size=3, stride=1),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.conv4_1 = nn.Conv2d(32, 1, kernel_size=1, stride=1)\n",
    "        self.conv4_2 = nn.Conv2d(32, 4, kernel_size=1, stride=1)\n",
    "        self.conv4_3 = nn.Conv2d(32, 10, kernel_size=1, stride=1,)\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layer(x)\n",
    "        det = torch.sigmoid(self.conv4_1(x))\n",
    "        box = self.conv4_2(x)\n",
    "        landmark = self.conv4_3(x)\n",
    "        return det, box, landmark\n",
    "\n",
    "    \n",
    "class R_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R_Net, self).__init__()\n",
    "        self.pre_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 28, kernel_size=3, stride=1),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(28, 48, kernel_size=3, stride=1),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(48, 64, kernel_size=2, stride=1),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Linear(64 * 2 * 2, 128)\n",
    "        self.prelu4 = nn.PReLU()\n",
    "        self.conv5_1 = nn.Linear(128, 1)\n",
    "        self.conv5_2 = nn.Linear(128, 4)\n",
    "        self.conv5_3 = nn.Linear(128, 10)\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conv4(x)\n",
    "        x = self.prelu4(x)\n",
    "        det = torch.sigmoid(self.conv5_1(x))\n",
    "        box = self.conv5_2(x)\n",
    "        landmark = self.conv5_3(x)\n",
    "        return det, box, landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box, boxes):\n",
    "\n",
    "    box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "    area = (boxes[2] - boxes[0] + 1) * (boxes[3] - boxes[1] + 1)\n",
    "    xx1 = np.maximum(box[0], boxes[0])\n",
    "    yy1 = np.maximum(box[1], boxes[1])\n",
    "    xx2 = np.minimum(box[2], boxes[2])\n",
    "    yy2 = np.minimum(box[3], boxes[3])\n",
    "\n",
    "    w = np.maximum(0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    ovr = np.true_divide(inter,(box_area + area - inter))\n",
    "    return ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_first_stage(image, net, scale, threshold):\n",
    "\n",
    "    width, height = image.size\n",
    "    sw, sh = math.ceil(width * scale), math.ceil(height * scale)\n",
    "    img = image.resize((sw, sh), Image.BILINEAR)\n",
    "    img = transforms.ToTensor()(img).unsqueeze(0)\n",
    "    img = img.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    output = net(img)\n",
    "    probs = output[0].data.cpu().numpy()[0, 0, :, :]\n",
    "    offsets = output[1].data.cpu().numpy()\n",
    "    boxes = _generate_bboxes(probs, offsets, scale, threshold)\n",
    "    if len(boxes) == 0:\n",
    "        return None\n",
    "\n",
    "    keep = nms(boxes[:, 0:5], overlap_threshold=0.5)\n",
    "    return boxes[keep]\n",
    "\n",
    "def _generate_bboxes(probs, offsets, scale, threshold):\n",
    "    stride = 2\n",
    "    cell_size = 12\n",
    "\n",
    "    inds = np.where(probs > threshold)\n",
    "    if inds[0].size == 0:\n",
    "        return np.array([])\n",
    "    tx1, ty1, tx2, ty2 = [offsets[0, i, inds[0], inds[1]] for i in range(4)]\n",
    "\n",
    "    offsets = np.array([tx1, ty1, tx2, ty2])\n",
    "    score = probs[inds[0], inds[1]]\n",
    "\n",
    "    bounding_boxes = np.vstack([\n",
    "        np.round((stride * inds[1] + 1.0) / scale),\n",
    "        np.round((stride * inds[0] + 1.0) / scale),\n",
    "        np.round((stride * inds[1] + 1.0 + cell_size) / scale),\n",
    "        np.round((stride * inds[0] + 1.0 + cell_size) / scale),\n",
    "        score, offsets\n",
    "    ])\n",
    "    return bounding_boxes.T\n",
    "\n",
    "def nms(boxes, overlap_threshold=0.5, mode='union'):\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    scores = boxes[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "\n",
    "        if mode is 'min':\n",
    "            ovr = inter / np.minimum(areas[i], areas[order[1:]])\n",
    "        else:\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= overlap_threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_square(bboxes):\n",
    "    square_bboxes = np.zeros_like(bboxes)\n",
    "    x1, y1, x2, y2 = [bboxes[:, i] for i in range(4)]\n",
    "    h = y2 - y1 + 1.0\n",
    "    w = x2 - x1 + 1.0\n",
    "    max_side = np.maximum(h, w)\n",
    "    square_bboxes[:, 0] = x1 + w * 0.5 - max_side * 0.5\n",
    "    square_bboxes[:, 1] = y1 + h * 0.5 - max_side * 0.5\n",
    "    square_bboxes[:, 2] = square_bboxes[:, 0] + max_side - 1.0\n",
    "    square_bboxes[:, 3] = square_bboxes[:, 1] + max_side - 1.0\n",
    "    return square_bboxes\n",
    "\n",
    "\n",
    "def calibrate_box(bboxes, offsets):\n",
    "\n",
    "    x1, y1, x2, y2 = [bboxes[:, i] for i in range(4)]\n",
    "    w = x2 - x1 + 1.0\n",
    "    h = y2 - y1 + 1.0\n",
    "    w = np.expand_dims(w, 1)\n",
    "    h = np.expand_dims(h, 1)\n",
    "\n",
    "    translation = np.hstack([w, h, w, h]) * offsets\n",
    "    bboxes[:, 0:4] = bboxes[:, 0:4] + translation\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def get_image_boxes(bounding_boxes, img, size=24):\n",
    "    num_boxes = len(bounding_boxes)\n",
    "    width, height = img.size\n",
    "\n",
    "    [dy, edy, dx, edx, y, ey, x, ex, w, h] = correct_bboxes(bounding_boxes, width, height)\n",
    "    img_boxes = np.zeros((num_boxes, 3, size, size), 'float32')\n",
    "\n",
    "    for i in range(num_boxes):\n",
    "        img_box = np.zeros((h[i], w[i], 3), 'uint8')\n",
    "        img_array = np.asarray(img, 'uint8')\n",
    "        img_box[dy[i]:(edy[i] + 1), dx[i]:(edx[i] + 1), :] = \\\n",
    "            img_array[y[i]:(ey[i] + 1), x[i]:(ex[i] + 1), :]\n",
    "        img_box = Image.fromarray(img_box)\n",
    "        img_box = img_box.resize((size, size), Image.BILINEAR)\n",
    "        img_box = np.asarray(img_box, 'float32')\n",
    "        img_boxes[i, :, :, :] = img_normalization(img_box)\n",
    "\n",
    "    return img_boxes\n",
    "\n",
    "\n",
    "def correct_bboxes(bboxes, width, height):\n",
    "    x1, y1, x2, y2 = [bboxes[:, i] for i in range(4)]\n",
    "    w, h = x2 - x1 + 1.0, y2 - y1 + 1.0\n",
    "    num_boxes = bboxes.shape[0]\n",
    "\n",
    "    x, y, ex, ey = x1, y1, x2, y2\n",
    "    dx, dy = np.zeros((num_boxes,)), np.zeros((num_boxes,))\n",
    "    edx, edy = w.copy() - 1.0, h.copy() - 1.0\n",
    "\n",
    "    ind = np.where(ex > width - 1.0)[0]\n",
    "    edx[ind] = w[ind] + width - 2.0 - ex[ind]\n",
    "    ex[ind] = width - 1.0\n",
    "\n",
    "    ind = np.where(ey > height - 1.0)[0]\n",
    "    edy[ind] = h[ind] + height - 2.0 - ey[ind]\n",
    "    ey[ind] = height - 1.0\n",
    "\n",
    "    ind = np.where(x < 0.0)[0]\n",
    "    dx[ind] = 0.0 - x[ind]\n",
    "    x[ind] = 0.0\n",
    "\n",
    "    ind = np.where(y < 0.0)[0]\n",
    "    dy[ind] = 0.0 - y[ind]\n",
    "    y[ind] = 0.0\n",
    "    return_list = [dy, edy, dx, edx, y, ey, x, ex, w, h]\n",
    "    return_list = [i.astype('int32') for i in return_list]\n",
    "\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def img_normalization(img):\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = (img - 127.5) * 0.0078125\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thresholds for P-Net is set to 0.85 and 0.5 to weed out more poorly predicted boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS = [0.85,0.03]\n",
    "NMS_THRESHOLDS = [0.5,0.9]\n",
    "MIN_FACE_SIZE = 15.0\n",
    "\n",
    "\n",
    "def pnet_boxes(img, pnet, min_face_size=MIN_FACE_SIZE, thresholds=THRESHOLDS, nms_thresholds=NMS_THRESHOLDS):\n",
    "    pnet.eval()\n",
    "    width, height = img.size\n",
    "    min_length = min(height, width)\n",
    "    min_detection_size = 12\n",
    "    factor = 0.707  # sqrt(0.5)\n",
    "    scales = []\n",
    "    m = min_detection_size / min_face_size\n",
    "    min_length *= m\n",
    "    factor_count = 0\n",
    "    while min_length > min_detection_size:\n",
    "        scales.append(m * factor ** factor_count)\n",
    "        min_length *= factor\n",
    "        factor_count += 1\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for s in scales:\n",
    "        boxes = run_first_stage(img, pnet, scale=s, threshold=thresholds[0])\n",
    "        bounding_boxes.append(boxes)\n",
    "\n",
    "    bounding_boxes = [i for i in bounding_boxes if i is not None]\n",
    "\n",
    "    try:\n",
    "        _ = bounding_boxes[0]\n",
    "    except Exception:\n",
    "        img.show()\n",
    "    if len(bounding_boxes) == 0:\n",
    "        return None\n",
    "    bounding_boxes = np.vstack(bounding_boxes)\n",
    "\n",
    "    keep = nms(bounding_boxes[:, 0:5], nms_thresholds[0])\n",
    "    bounding_boxes = bounding_boxes[keep]\n",
    "    bounding_boxes = calibrate_box(bounding_boxes[:, 0:5], bounding_boxes[:, 5:])\n",
    "    bounding_boxes = convert_to_square(bounding_boxes)\n",
    "    bounding_boxes[:, 0:4] = np.round(bounding_boxes[:, 0:4])\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "def rnet_boxes(img, rnet, bounding_boxes, thresholds=THRESHOLDS, nms_thresholds=NMS_THRESHOLDS):\n",
    "    rnet.eval()\n",
    "    img_boxes = get_image_boxes(bounding_boxes, img, size=24)\n",
    "    img_boxes = torch.FloatTensor(img_boxes)\n",
    "    img_boxes=img_boxes.cuda()\n",
    "    output = rnet(img_boxes)\n",
    "    probs = output[0].data.cpu().numpy()\n",
    "    offsets = output[1].data.cpu().numpy()\n",
    "\n",
    "    keep = np.where(probs[:, 0] > thresholds[1])[0]\n",
    "    bounding_boxes = bounding_boxes[keep]\n",
    "    bounding_boxes[:, 4] = probs[keep, 0].reshape((-1,))\n",
    "    offsets = offsets[keep]\n",
    "\n",
    "    keep = nms(bounding_boxes, nms_thresholds[1])\n",
    "    bounding_boxes = bounding_boxes[keep]\n",
    "    bounding_boxes = calibrate_box(bounding_boxes, offsets[keep])\n",
    "    bounding_boxes = convert_to_square(bounding_boxes)\n",
    "    bounding_boxes[:, 0:4] = np.round(bounding_boxes[:, 0:4])\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global DEVICE\n",
    "DEVICE = torch.device('cuda:0')\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    \n",
    "\n",
    "pnet=P_Net().cuda()\n",
    "pnet.load_state_dict(torch.load('/kaggle/input/trainedmtcnn/PNet3.pth'))\n",
    "rnet=R_Net().cuda()\n",
    "rnet.load_state_dict(torch.load('/kaggle/input/trainedmtcnn/RNet_sl3.pth'))\n",
    "\n",
    "\n",
    "trainset = getlandmark('train')\n",
    "evalset = getlandmark('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generate training & evaluation data for R-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_landmark_offset(box, ldmk):\n",
    "    minx, miny = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ldmk_offset = [(ldmk[i] - [minx, miny][i % 2]) / float([w, h][i % 2]) for i in range(len(ldmk))]\n",
    "    return ldmk_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 0\n",
      "working on 100\n",
      "working on 200\n",
      "working on 300\n",
      "working on 400\n",
      "working on 500\n",
      "working on 600\n",
      "working on 700\n",
      "working on 800\n",
      "working on 900\n",
      "working on 1000\n",
      "working on 1100\n",
      "working on 1200\n",
      "working on 1300\n",
      "working on 1400\n",
      "working on 1500\n",
      "working on 1600\n",
      "working on 1700\n",
      "working on 1800\n",
      "working on 1900\n",
      "working on 2000\n",
      "working on 2100\n",
      "working on 2200\n",
      "working on 2300\n",
      "working on 2400\n",
      "working on 2500\n",
      "working on 2600\n",
      "working on 2700\n",
      "working on 2800\n",
      "working on 2900\n",
      "working on 3000\n",
      "working on 3100\n",
      "working on 3200\n",
      "working on 3300\n",
      "working on 3400\n",
      "working on 3500\n",
      "working on 3600\n",
      "working on 3700\n",
      "working on 3800\n",
      "working on 3900\n",
      "working on 4000\n",
      "working on 4100\n",
      "working on 4200\n",
      "working on 4300\n",
      "working on 4400\n",
      "working on 4500\n",
      "working on 4600\n",
      "working on 4700\n",
      "working on 4800\n",
      "working on 4900\n",
      "working on 5000\n",
      "working on 5100\n",
      "working on 5200\n",
      "working on 5300\n",
      "working on 5400\n",
      "working on 5500\n",
      "working on 5600\n",
      "working on 5700\n",
      "working on 5800\n",
      "working on 5900\n",
      "working on 6000\n",
      "working on 6100\n",
      "working on 6200\n",
      "working on 6300\n",
      "working on 6400\n",
      "working on 6500\n",
      "working on 6600\n",
      "working on 6700\n",
      "working on 6800\n",
      "working on 6900\n",
      "working on 7000\n",
      "working on 7100\n",
      "working on 7200\n",
      "working on 7300\n",
      "working on 7400\n",
      "working on 7500\n",
      "working on 7600\n",
      "working on 7700\n",
      "working on 7800\n",
      "working on 7900\n",
      "working on 8000\n",
      "working on 8100\n",
      "working on 8200\n",
      "working on 8300\n",
      "working on 8400\n",
      "working on 8500\n",
      "working on 8600\n",
      "working on 8700\n",
      "working on 8800\n",
      "working on 8900\n",
      "working on 9000\n",
      "working on 9100\n",
      "working on 9200\n",
      "working on 9300\n",
      "working on 9400\n",
      "working on 9500\n",
      "working on 9600\n",
      "working on 9700\n",
      "working on 9800\n",
      "working on 9900\n",
      "Complete in 4m 15s\n"
     ]
    }
   ],
   "source": [
    "rnet_train_data = open('/kaggle/working/rnet_train_lm.txt','w')\n",
    "\n",
    "\n",
    "iou_th = {'n': (0, 0.3), 'pf': (0.4, 0.65), 'p': (0.65, 1.0)}\n",
    "since = time.time()\n",
    "\n",
    "for num,(img_pth, face, landmark) in enumerate(trainset):\n",
    "    if num%100==0:\n",
    "        print('working on '+str(num))\n",
    "    \n",
    "    try:\n",
    "        i = Image.open(img_pth)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    image = Image.open(img_pth)\n",
    "    bounding_boxes = pnet_boxes(image, pnet)\n",
    "    if bounding_boxes is None:\n",
    "        continue\n",
    "    bounding_boxes_rnet = rnet_boxes(image, rnet, bounding_boxes)\n",
    "    if len(bounding_boxes_rnet) != 0:\n",
    "        bounding_boxes = np.vstack((bounding_boxes, bounding_boxes_rnet))\n",
    "    \n",
    "    face = np.array([face[0],face[2],face[1],face[3]])\n",
    "    width, height = image.size\n",
    "    total = len(bounding_boxes)\n",
    "    \n",
    "    rnet_train_data.write(img_pth+'|')\n",
    "    for id, box in enumerate(bounding_boxes, start=1):\n",
    "        box = [min(max(0, int(box[i])), width if i % 2 == 0 else height) for i in range(4)]\n",
    "        if box[2] - box[0] < 24: continue\n",
    "        iou = IoU(box, face)\n",
    "        \n",
    "        for temp_label in iou_th:\n",
    "            if iou < iou_th[temp_label][0] or iou > iou_th[temp_label][1]:\n",
    "                continue\n",
    "            else:\n",
    "                label = temp_label\n",
    "                ldmk_offset = ' '.join([str(i) for i in cal_landmark_offset(box, landmark)])\n",
    "                gt_box = ' '.join([str(i) for i in face]) \n",
    "                crop_box = ' '.join([str(i) for i in box]) \n",
    "                \n",
    "                rnet_train_data.write('|'+label+'+'+gt_box+'+'+crop_box+'+'+ldmk_offset)\n",
    "    rnet_train_data.write('\\n')\n",
    "rnet_train_data.close()\n",
    "\n",
    "spent = time.time() - since\n",
    "print('Complete in {:.0f}m {:.0f}s'.format(spent // 60, spent % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate evaluation data for R-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 0\n",
      "working on 100\n",
      "working on 200\n",
      "working on 300\n",
      "working on 400\n",
      "working on 500\n",
      "working on 600\n",
      "working on 700\n",
      "working on 800\n",
      "working on 900\n",
      "working on 1000\n",
      "working on 1100\n",
      "working on 1200\n",
      "working on 1300\n",
      "working on 1400\n",
      "working on 1500\n",
      "working on 1600\n",
      "working on 1700\n",
      "working on 1800\n",
      "working on 1900\n",
      "working on 2000\n",
      "working on 2100\n",
      "working on 2200\n",
      "working on 2300\n",
      "working on 2400\n",
      "working on 2500\n",
      "working on 2600\n",
      "working on 2700\n",
      "working on 2800\n",
      "working on 2900\n",
      "working on 3000\n",
      "working on 3100\n",
      "working on 3200\n",
      "working on 3300\n",
      "working on 3400\n",
      "Complete in 1m 26s\n"
     ]
    }
   ],
   "source": [
    "rnet_eval_data = open('/kaggle/working/rnet_eval_lm.txt','w')\n",
    "\n",
    "iou_th = {'n': (0, 0.3), 'pf': (0.4, 0.65), 'p': (0.65, 1.0)}\n",
    "since = time.time()\n",
    "\n",
    "for num,(img_pth, face, landmark) in enumerate(evalset):\n",
    "    if num%100==0:\n",
    "        print('working on '+str(num))\n",
    "    \n",
    "    try:\n",
    "        i = Image.open(img_pth)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    image = Image.open(img_pth)\n",
    "    bounding_boxes = pnet_boxes(image, pnet)\n",
    "    if bounding_boxes is None:\n",
    "        continue\n",
    "    bounding_boxes_rnet = rnet_boxes(image, rnet, bounding_boxes)\n",
    "    if len(bounding_boxes_rnet) != 0:\n",
    "        bounding_boxes = np.vstack((bounding_boxes, bounding_boxes_rnet))\n",
    "    \n",
    "    face = np.array([face[0],face[2],face[1],face[3]])\n",
    "    \n",
    "    width, height = image.size\n",
    "    total = len(bounding_boxes)\n",
    "    \n",
    "    rnet_eval_data.write(img_pth+'|')\n",
    "    for id, box in enumerate(bounding_boxes, start=1):\n",
    "        box = [min(max(0, int(box[i])), width if i % 2 == 0 else height) for i in range(4)]\n",
    "        if box[2] - box[0] < 24: continue\n",
    "        iou = IoU(box, face)\n",
    "        \n",
    "        for temp_label in iou_th:\n",
    "            if iou < iou_th[temp_label][0] or iou > iou_th[temp_label][1]:\n",
    "                continue\n",
    "            else:\n",
    "                label = temp_label\n",
    "                ldmk_offset = ' '.join([str(i) for i in cal_landmark_offset(box, landmark)])\n",
    "                gt_box = ' '.join([str(i) for i in face]) \n",
    "                crop_box = ' '.join([str(i) for i in box]) \n",
    "                \n",
    "                rnet_eval_data.write('|'+label+'+'+gt_box+'+'+crop_box+'+'+ldmk_offset)\n",
    "    rnet_eval_data.write('\\n')\n",
    "rnet_eval_data.close()\n",
    "\n",
    "spent = time.time() - since\n",
    "print('Complete in {:.0f}m {:.0f}s'.format(spent // 60, spent % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
